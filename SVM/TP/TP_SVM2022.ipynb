{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RIO2xYEVmNQr"
   },
   "source": [
    "# TP de SVM\n",
    "\n",
    "L'objectif de ce TP est se de former à l'utilisation des SVMs en analyse d'images. Nous allons étudier dans un premier temps le cas d'une classification de l'ensemble d'une image (cas où une image = un point ou échantillon). Dans un second temps nous nous intéressons à la classification d'occupation des sols à partir d'imagerie satellitaire (cas où un pixel = un point). \n",
    "\n",
    "La première partie est réalisée sous Python afin de vous familiariser au SVM. La seconde partie sera réalisée avec un logiciel de télédétection (Orfeo Toolbox) afin de vous former à l'utilisation d'outils utiles pour vos stages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4CxXQg4pmPHQ"
   },
   "source": [
    "## Première partie\n",
    "\n",
    "Cette partie a pour objectif de vous familiariser avec le SVM sur des cas simples. Pour ce faire, nous allons commencer par entraîner un SVM à distinguer des chiffres présents sur des petites vignettes. Dans un second temps nous entraînerons le SVM à réaliser une reconnaissance faciale. Nous tenterons également de comprendre l'influence des paramètres sur les résultats du SVM et comment les optimiser.\n",
    "\n",
    "Nous nous appuyons sur l'implémentation en Python du SVM fournie par la librairie de machine learning scikit-learn. Ce TP ne demande aucune connaissance poussée en Python. \n",
    "\n",
    "Il est vivement recommandé de consulter la documentation de scikit-learn sur le SVM ( https://scikit-learn.org/stable/modules/svm.html ) puisqu'elle fournit une première idée de la syntaxe du SVM pour son utilisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z-PukIoXmZJf"
   },
   "source": [
    "Ci-dessous, nous importons les librairies utilisées dans ce TP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2814,
     "status": "ok",
     "timestamp": 1673458235601,
     "user": {
      "displayName": "Alexandre Hippert-Ferrer",
      "userId": "08310625332108864165"
     },
     "user_tz": -60
    },
    "id": "5yGkjZixmSP6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gdal\n",
    "import gdalconst\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,StratifiedKFold\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets, svm\n",
    "from sklearn.metrics import precision_recall_fscore_support,classification_report,confusion_matrix\n",
    "from sklearn.feature_selection import RFE,RFECV\n",
    "\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "\n",
    "np.random.seed(31415)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FNEZMf4Zm9Q2"
   },
   "source": [
    "### Reconnaisance de chiffres\n",
    "\n",
    "Nous allons nous servir d'un jeu de données directement disponible sous scikit-learn contenant un ensemble d'image de chiffre. L'objectif est d'obtenir un classifieur reconnaisant les chiffres présents sur des images.\n",
    "\n",
    "On représente le jeu de données par $(x_i, y_i)_{i=1}^n$, où $x_i$ est la $i$ème image, $y_i \\in \\{1,\\dots,10\\}$ est son label associé et $n$ est le nombre d'images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bkd0Z_9UnLj2"
   },
   "outputs": [],
   "source": [
    "dataset = datasets.load_digits()\n",
    "images=dataset.images\n",
    "labels=dataset.target\n",
    "shape=images.shape\n",
    "print(\"Le jeu contient {} images de taille {}x{}\".format(shape[0],shape[1],shape[2]))\n",
    "print(\"La variable image est un array de dimension nb_images*nb_lignes*nb_colonnes. \\nLa variable labels est un array de dimension nb_images contenant la classe de chaque images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MbZ4cFDgnP9J"
   },
   "source": [
    "1. Écrire **une fonction** plot() permettant d'afficher quelques images et leurs labels associés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1tCamCibnQwI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05EY2MMwnUiR"
   },
   "source": [
    "2. Pour la suite du TP, il est intéressant de réécrire les images actuellement sous la forme d'un array de dimension (nb_images, nb_lignes, nb_colonnes) sous la forme d'un array (nb_images, nb_pixels). Écrire une fonction reshape() prenant un array de dimension (nb_images, nb_lignes, nb_colonnes) et le renvoyant sous la forme d'une matrice (nb_images, nb_pixels).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uhAl1Xf5nhrQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PuPsTHbMnlRY"
   },
   "source": [
    "3. Nous disposons de suffisamment de données (64 images de 1797 pixels) afin séparer notre jeu de données en un jeu d'**entraînement** $(x_{train}, y_{train})$ et un jeu de **test** $(x_{test}, y_{test})$. Notre SVM apprendra sur le jeu d'entraînement et ses performances seront évaluées sur le jeu de test. Écrire une fonction séparant en deux jeux distincts (entraînement et test) notre jeu de données. La séparation doit être **aléatoire** et si l'image $x_i$ est attribuée au jeu de test, son label $y_i$ doit l'être aussi.\n",
    "\n",
    "**Indication** : pour cette question, on pourra directement utiliser la fonction train_test_split() de scikit-learn. Assurez-vous de bien avoir compris ce que réalise cette fonction avant de passer à la suite. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bJCHfeiKnmrW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YNBdES1znsJE"
   },
   "source": [
    "4. Écrire le code (deux lignes suffisent) qui réalise l'entraînement du SVM pour un noyau et un paramétrage donnés, sur les données d'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fezGVe6intFD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XD2StEMbnyFk"
   },
   "source": [
    "5. Écrire le code (une ligne) qui permet de tester le modèle (que nous venons d'entraîner en Q4) sur les données de test. On utilisera la fonction predict() de la classe SVM(), qui renvoie les prédictions sur le jeu de test, c-a-d la classe supposée de chaque image du jeu de test. Attention, ici, nous n'avons pas besoin de $y_{test}$ !\n",
    "\n",
    "Quelle est la différence entre les fonctions fit() et predict() ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mP68Ea2snywn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HR2Bge8zn1TH"
   },
   "source": [
    "6. Écrire une fonction stats() qui affiche la précision, le rappel et le f-score pour chaque classe ainsi que la matrice de confusion. Elle affiche également quelques images avec leurs prédictions.\n",
    "\n",
    "**Indication** : on utilisera successivement les fonctions classification_report() et confusion_matrix() de scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1zr9sO4Nn15V"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gbvDt9F8n7F3"
   },
   "source": [
    "**Félicitations** ! Vous avez entrainé votre tout premier SVM et il donne des résultats très convainquants. Au vu de ces performances, il ne semble pas nécessaire de chercher à optimiser ses résultats.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yAvW7F5Fn8zf"
   },
   "source": [
    "7. Bien que la sélection d'attributs ne soit pas utile dans le cas présent (calcul très rapide), je vous propose de vous interroger sur la pertinence de certains attributs.\n",
    "   - À quoi correspond un attribut dans le cas présent ?\n",
    "   - Combien d'attributs comporte le problème ?\n",
    "   - Lesquels vous paraît-il possible d'enlever sans impacter la qualité du classifieur ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EUQxaxrUoI_P"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tVx8PWI4ofLt"
   },
   "source": [
    "8. Implémenter une fonction s'appuyant sur le RFE et la CV (cross-validation) pour déterminer à partir de combien d'attributs les performances atteignent un palier.\n",
    "\n",
    "**Indication** : encore une fois, scikit-learn fait bien les choses. On pourra utiliser la classe RFECV() avec un SVM comme estimateur. À vous de régler les autres paramètres (step, cv, scoring, *etc.*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s4TccGEPn739"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qnLI0El-okqF"
   },
   "source": [
    "9.  Montrer les pixels correspondant aux $n$ attributs à conserver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y8SFgUMiolSW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EUdBbXp8oqY2"
   },
   "source": [
    "### Reconnaissance de visage\n",
    "\n",
    "Cette partie aborde brièvement la reconnaissance de visage à l'aide d'un SVM. Elle a vocation à permettre de mieux comprendre l'influence des différents paramètres sur le SVM avec un exemple moins simple que le précédent, c'est-à-dire nécessitant une **optimisation**.\n",
    "\n",
    "Il est important de noter qu'en pratique on préfèrera des méthodes de deep learning pour ce genre d'application !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WaOkdqFmo0ib"
   },
   "outputs": [],
   "source": [
    "dataset=fetch_lfw_people( resize=1, min_faces_per_person=50, color=True, download_if_missing=True)\n",
    "images=dataset.images\n",
    "labels=dataset.target\n",
    "name=dataset.target_names\n",
    "name=[name[i] for i in labels]\n",
    "shape=images.shape\n",
    "print(\"Le jeu contient {} images de taille {}x{}\".format(shape[0],shape[1],shape[2]))\n",
    "print(\"La variable image est un array de dimension nb_images*nb_lignes*nb_colonnes*nb_couleurs. \\nLa variable labels est un array de dimension nb_images contenant la classe de chaque images\")\n",
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "print(\"il y a {} personnes différentes dans le jeu de données\".format(len(unique)))\n",
    "plot(images,name,normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mElmTDQno6Q8"
   },
   "source": [
    "1. En vous servant du code précédent, redimensionnez vos données correctement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o1aASfOFpC3e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6vvAeAfTpDwV"
   },
   "source": [
    "2. Notre espace de description ayant un très grand nombre de dimensions (nb_couleurs * nb_lignes * nb_colonnes), nous allons devoir réduire le nombre de dimensions. Pour ce faire, nous allons procéder par analyse en composante principales (ACP), une méthode par filtre (plus rapide que SVM-RFE) très utilisée en reconnaissance faciale et en télédétection. L'ACP comme le SVM sont des méthodes sensibles aux fortes variations d'amplitudes entre les attributs. Les variations dans ce jeu de données étant fortes, il est important de **standardiser** les données. Utiliser le StandardScaler() de scikit-learn pour réaliser la standardisation (trois lignes de code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vaGPnJvxpHD2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6QJSij_MpPPW"
   },
   "source": [
    "3. Séparez le jeu de données standardisé en un jeu d'entraînement et un jeu de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eKmu114qpQBP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e3VV2m9fpSp2"
   },
   "source": [
    "4. Écrire le code réalisant une ACP s'ajustant aux données d'entraînement et l'appliquer à la fois aux données d'entraînement et de test. Elle doit renvoyer $k$ attributs pour chaque image ($k=150$ est un bon choix pour commencer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6E4-NdghpcDX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P6rXauF8pdM8"
   },
   "source": [
    "5. Entrainez le SVM et évaluez ses résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vczUxbUOpoQv"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RzV9DdUrptYp"
   },
   "source": [
    "6. On constate ici que les résultats sont loin d'être aussi bons que précédemment. Nous allons donc tenter d'optimiser les paramètres de notre SVM. Essayez de jouer \"à la main\" sur les paramètres C et les paramètres de noyaux pour voir leur impact sur la qualité des résultats. Vous pouvez également jouer sur la métrique à optimiser (précision, rappel, fscore). \n",
    "\n",
    "7. Nous allons maintenant tenter d'écrire une fonction permettant de déterminer plus efficacement les résultats optimaux de notre méthode. Cette fonction va nécessairement devoir entrainer plusieurs fois le SVM avec différents paramètres et évaluer à chaque fois les résultats pour ne retenir que le meilleur paramétrage. \n",
    "  * L'évaluation de la qualité des résultats ne peut pas se faire sur le jeu de test. Pourquoi ?\n",
    "  * Proposer deux solutions permettant de contourner ce problème."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bkdklO8FpwIR"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gSVNM-Ldp7vj"
   },
   "source": [
    "8. Écrire une version évoluée du code de la question 4 dans une fonction train_SVM(), de sorte qu'elle procède à une cross-validation pour déterminer les meilleurs paramètres du SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sf1-TW8cpuwu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tyKlhswCqLG_"
   },
   "source": [
    "## Partie 2: réaliser une classification d'occupation des sols\n",
    "\n",
    "Cette partie du TP s'effectue à l'aide du logiciel Orfeo toolbox https://www.orfeo-toolbox.org/. Nous allons ici utiliser son interface simple. Sachez qu'il est également possible de se servir de QGIS, de l'interface graphique propre d'OTB, ou de Python pour utiliser OTB.\n",
    "L'objectif est de réaliser la classification d'occupation des sols d'une image sentinel 2.\n",
    "\n",
    "Les images Sentinel 2 sont des images optiques à 13 bandes. Les bandes vont de B1 (bleu) à B12 (moyen infra-rouge). Les bandes RVB classiques sont B2 (bleu), B3 (vert), B4 (rouge). Les bandes B8 et B8A sont les bandes du proche infra-rouge. Les bandes ont des résolutions différentes (10m, 20m, 60m). Pour former une unique image nous les avons toutes ré-échantillonnées à 10m."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H5ZlrvQxqYJE"
   },
   "source": [
    "1. Ouvrir le projet sous QGIS pour avoir un premier aperçu des données.\n",
    "\n",
    "\n",
    "Il est nécessaire de disposer d'un jeu d'entrainement et de \n",
    "validation pour entrainer notre classifieur. Plusieurs approches sont \n",
    "possible pour en obtenir un : enquête terrain, utilisation de données \n",
    "d'occupation des sols (OCS-GE par exemple), ou simplement par \n",
    "photo-interprétation. Chacune de ces méthodes présente son lot \n",
    "d'avantages et d'inconvénients :\n",
    "  - Les enquêtes terrains sont longues à mettre en place et ne couvrent généralement qu'une petite zone. Elles ont pour avantage de permettre la construction d'un jeu de données fiables !\n",
    "  - Les données déjà établies d'occupation des sols sont des jeux d'entrainement beaucoup plus rapide à utiliser. Ils ont deux inconvénients majeurs : ils contiennent des erreurs pouvant fausser votre algorithme et vous n'en trouverez pas nécessairement un réalisé à la même époque que votre image.\n",
    "  - La photo-interprétation rend plus rapide la création du jeu de données que par enquêtes terrain mais plus longue que par l'utilisation de données pré-existantes. Un risque est de mal photo-interpréter les images et donc d'inclure des erreurs.\n",
    "\n",
    "\n",
    " 2. Créer un jeu de données par photo-interprétation :\n",
    "\n",
    "      -  Créer une nouvelle couche shapefile contenant un unique attribut \n",
    "        classe de type integer et acceptant des géométries de type polygones.\n",
    "      -  Tracez un premier polygone sur une zone de forêt et attribuez-lui la\n",
    "         classe 1. Tracer ainsi 4 à 5 polygones sur différentes zones de forêt \n",
    "        dans l'image. \n",
    "      -   Recommencer cette étape sur des zones de différentes natures (eau, \n",
    "        bâti, champ moissonné, culture ...) en leur attribuant respectivement la classe (2,3,4,5 ...).\n",
    "\n",
    "3. Connaissez-vous un indice permettant de mieux distinguer le bâti du non-bâti ?\n",
    "\n",
    "  - Ajouter cet indice à votre image. Pour ce faire, ouvrez le fichier intitulé mapla.bat du répertoire otb. La fenêtre qui s'ouvre vous montre toutes les fonctions existantes. Sélectionnez bandmathx et ajoutez votre 14ème bande.\n",
    "\n",
    "4.  OTB réalisera pour nous la normalisation des données si on lui fournit les statistiques de chaque bande de l'image. Pour calculer ces statistiques, sélectionnez ComputeImageStatistic. Stockez le résultat dans un fichier stat.xml.\n",
    "\n",
    "5.  Nous n'avons pas besoin de séparer notre jeu de données en un jeu de test et un jeu d'entraînement car OTB s'en charge pour nous ! Nous allons donc maintenant pouvoir entrainer notre classifieur. Pour cela, sélectionnez TrainImageClassifier. N'oubliez pas de fournir le fichier stat.xml. Sauvegardez le modèle dans un fichier modele.txt. Choisir un SVM avec un noyau linéaire. Pour le premier essai, ne pas choisir l'option d'optimisation des paramètres. Une fois qu'il a fini de tourner,allez dans l'onglet log pour regarder la matrice de confusion, la précision, le rappel et le fscore. Choisir d'optimiser les paramètres et recommencez.\n",
    "\n",
    "6.  Maintenant que nous avons un modèle il ne nous reste plus qu'à classer l'image. Pour ce faire sélectionnez ImageClassifier. N'oubliez pas de fournir le fichier stat.xml. Regardez et analysez le résultat sous QGIS.\n",
    "\n",
    "7. On constate un léger effet poivre et sel (quelques pixels épars mal classés). Pour cela utilisez QGIS. Pour améliorer le rendu, procédez à un tamisage. Il vous faut alors théoriquement ré-évaluer vos résultats, ce qu'on ne fera pas dans ce TP pour des raisons de temps.\n",
    "\n",
    "8. S'il vous reste du temps, recommencez les étapes 3 à 5 avec d'autres classifieurs et tentez de voir le rendu d'une ACP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wf86y81Eq_d9"
   },
   "source": [
    "**Si vous désirez conserver une copie de ce TP au format pdf : ouvrez une console et taper jupyter nbconvert --to pdf tp_svm.ipynb**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1xqeB5YwhsnueVkk9FVMnsQtpB_bYL2Bg",
     "timestamp": 1673366156904
    },
    {
     "file_id": "1fcTw6SeaNmxRa89GbQ7PwLqFpYyYEW7v",
     "timestamp": 1606717959975
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
